{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9H0KBqW34qY"
      },
      "source": [
        "# MNIST Dataset Analysis\n",
        "\n",
        "The MNIST dataset is a classic dataset in machine learning, consisting of handwritten digits from 0 to 9. It is widely used for training and testing various image processing algorithms. This notebook demonstrates how to load and explore the MNIST dataset using TensorFlow.\n",
        "\n",
        "## Dataset Attribution\n",
        "\n",
        "The MNIST dataset was introduced in the following paper:\n",
        "\n",
        "**Title:** Gradient-Based Learning Applied to Document Recognition  \n",
        "**Authors:** Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner  \n",
        "**Journal:** Proceedings of the IEEE  \n",
        "**Volume:** 86  \n",
        "**Number:** 11  \n",
        "**Pages:** 2278–2324  \n",
        "**Year:** 1998\n",
        "\n",
        "Please refer to this paper for more details on the dataset and its use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cif9FW734vty"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "The first step in this project is to import the libraries that will be needed hereafter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_06sApifAKHS"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDeqCy_c5M4d"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "Keras comes built-in with various datasets, one of them being the MNIST Dataset. This is the dataset I will be working for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pesXwCmSARnQ",
        "outputId": "6eeab223-45d8-4bcb-9bea-218ecc48ef35"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgjjWnF_vjUh"
      },
      "source": [
        "Now that I have the images and the labels, I now want to know the data types of the images and labels. The result is they're all NumPy Arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh4gwW4svaXf",
        "outputId": "3d98f210-2cbc-44f9-af0e-1a74218ccaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_images))\n",
        "print(type(train_labels))\n",
        "print(type(test_images))\n",
        "print(type(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4Yf43S-In21"
      },
      "source": [
        "Now I want to analyze the shapes of all the different NumPy Arrays. This will be helpful later on, once we start working with **Data Pre-Processing**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP2l41LKBRNo",
        "outputId": "822a6ec1-8c9a-4ade-dffd-8e52690a3057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu_-8HHP5Phi"
      },
      "source": [
        "# Data Pre-Processing\n",
        "\n",
        "In order to start working with the data, I first have to **reshape** the data and then **normalize** it.\n",
        "\n",
        "## Data Reshaping\n",
        "\n",
        "The reasoning behind reshaping the data is because neural networks, especially those designed for image classification, often expect input data in a specific format. The MNIST dataset consists of grayscale images of handwritten digits, each of size **28x28** pixels. The raw image data is stored as a **2D array** of shape **(28, 28)**, but neural networks typically expect input data in a **4D tensor** format, especially when using deep learning frameworks. The format of this **4D tensor** is [batch_size, height, width, channels].\n",
        "\n",
        "The elements in the 4D tensor are explained below:\n",
        "  - Batch Size: This dimension represents the number of images in a batch.\n",
        "  - Height and Width: These dimensions represent the spatial dimensions of the image.\n",
        "  - Channels: This dimension represents the color channels of the image. For grayscale images, this is 1, while for RGB images, it would be 3.\n",
        "\n",
        "## Data Normalization\n",
        "\n",
        "To ensure effective neural network training, pixel values are often normalized from the range [0, 255] to [0, 1]. This normalization process involves dividing by 255, a step that is necessary because pixel values are originally represented in an 8-bit format, known in NumPy as 'numpy.uint8'. This format uses integers ranging from 0 to 255, as an 8-bit value can represent 256 distinct states (from 0 to 255).\n",
        "\n",
        "To perform normalization, these integer values need to be converted to a floating-point type, such as 'float32'. This conversion is crucial because dividing integers directly can lead to precision issues. By converting to float and then dividing by 255, each pixel value is scaled to a decimal between 0 and 1.\n",
        "\n",
        "In the context of RGB images, where each color channel has 256 possible values, the total number of color combinations is 256^3. However, for grayscale images, we only need to consider the 256 possible values for a single channel.\n",
        "\n",
        "## Convert categorical labels to one-hot encoded format\n",
        "\n",
        "The 'to_categorical' method converts the Labels NumPy Array into an array containing multiple arrays (also called an object array). This applies a one-hot encoding format to each object (arrays) inside the main NumPy object Array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "laicb6XjAmOF"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((train_images.shape[0], 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((test_images.shape[0], 28 * 28)).astype('float32') / 225\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels  = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdYxhtXl5EZk"
      },
      "source": [
        "# Predictive Analytics\n",
        "\n",
        "## Introduction to the model\n",
        "\n",
        "The TensorFlow (or Keras) Sequential model is a linear stack of layers where each layer has exactly one input tensor and one output tensor, designed for building simple, straightforward neural networks in a step-by-step manner.\n",
        "\n",
        "## Creating an instance of the model\n",
        "\n",
        "The first step in creating and working with the model is to create an instance of the Sequential model.\n",
        "\n",
        "## Add layers to the model\n",
        "\n",
        "The next step is to add layers to the model. The model has a total of three layers. The input layer, the hidden layer, and the output layer.\n",
        "\n",
        "**The input layer** is created implicitly by **the first Dense layer**. The input shape is specified in **the first Dense layer**, which implicitly defines the input layer. The input layer consists of 784 neurons (since the input images are 28x28 pixels, flattened to a single vector of 784 pixels).\n",
        "\n",
        "**The first Dense layer**, or **the hidden layer**, acts as an intermediate layer that processes the input data, allowing the network to learn complex representations of the input. It contains **512 units (or neurons)** and uses the ReLu activation function. **The ReLU (Rectified Linear Unit)** is a popular **activation function** because it introduces non-linearity to the model while being computationally efficient.\n",
        "\n",
        "**The second Dense layer**, or **the output layer**, produces the final output of the network, which in this case is a probability distribution over the 10 classes (digits 0-9). It contains **10 units (or neurons)** (10 classes) and uses the softmax activation function. **The softmax activation function** is used in **the output layer** for multi-class classification problems.\n",
        "\n",
        "## Compile the model\n",
        "\n",
        "The next step is to compile the model. Compiling a model configures it for training by specifying the optimizer, loss function, and metrics to be evaluated. This step translates the model's high-level architecture into a format suitable for training and evaluation.\n",
        "\n",
        "### Optimizer\n",
        "\n",
        "The **optimizer** used in this model is the **RMSprop (Root Mean Square Propagation) Optimizer**. RMSprop is particularly effective for training deep neural networks.\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "The **loss function** used in this model is the **Categorical Crossentropy Loss Function**. This is the standard loss function used for multi-class classification problems where the target variable is one-hot encoded (as is the case with the MNIST Dataset).\n",
        "\n",
        "### Metrics\n",
        "\n",
        "The metric used to evaluate this model is **Accuracy**. Accuracy measures the proportion of correctly classified samples out of the total samples. It is a commonly used metric for classification tasks.\n",
        "\n",
        "## Fit the model\n",
        "\n",
        "The final step in creating our model is to fit the model. The `.fit()` method initiates the training process on the provided data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW_ANTxz_Zhw",
        "outputId": "ed98b99b-e27d-4a38-b0b1-6cf5a9882a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.4413\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.1150\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0696\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0503\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0357\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x3698ce310>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28, )))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMUQsunQ2IOJ"
      },
      "source": [
        "# Predicting the value of a single, random image\n",
        "\n",
        "## Define the Process Image Function\n",
        "\n",
        "The first step in this stage is to define the **Process Image function** which pre-processes the image in order to change the image's dimensions.\n",
        "\n",
        "The `.flatten()` method converts a multi-dimensional image array into a one-dimensional array.\n",
        "\n",
        "The `np.expand_dims()` expression adds an extra dimension to the array at the specified axis. By adding a new axis at the 0th position, it essentially converts the **1D array** into a **2D array** where the first dimension is 1. This is used to make the image compatible with machine learning models that expect a batch dimension.\n",
        "\n",
        "The function then returns the image.\n",
        "\n",
        "## Select a random image (and pass it to the function)\n",
        "\n",
        "The next step is to select a random image from the dataset.\n",
        "\n",
        "## Display the image\n",
        "\n",
        "After the image is selected, the next step is to use the **Matplotlib** library to plot the image.\n",
        "\n",
        "## Get the predicted value (label)\n",
        "\n",
        "In order to test the predictions on a more granular level, we apply the `.predict()` method to the pre-processed image. This will only get the prediction of a single image and allow us to see both the image and the predicted integer-equivalent value (label), as well as the probability of the selected class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6AV6pOkr6aPc"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    image = image.flatten()\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEkgHdnq2JYw",
        "outputId": "aec4c316-8f9c-40df-8c81-d8244c3ddc92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed image shape: (1, 784)\n"
          ]
        }
      ],
      "source": [
        "random_num = random.randint(0, len(test_images))\n",
        "\n",
        "single_image = test_images[random_num]\n",
        "preprocessed_image = preprocess_image(single_image)\n",
        "print(\"Preprocessed image shape:\", preprocessed_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "rJjS95_P5OXk",
        "outputId": "e496bb2e-701e-43ff-bcf7-3b335e391e1a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "first_image = np.array(preprocessed_image, dtype='float')\n",
        "pixels = first_image.reshape((28, 28))\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BepfNw96gbH",
        "outputId": "0238f1e7-5c8d-4525-9a14-8cc70f3c53fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Predicted class: 9\n",
            "This is the probability: 0.9996776580810547\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    predictions = model.predict(preprocessed_image)\n",
        "    #print('These are the predictions:')\n",
        "    #print(predictions)\n",
        "\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    print(f'Predicted class: {predicted_class}')\n",
        "\n",
        "    print(f'This is the probability: {predictions.max()}')\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baniwBBn4toP"
      },
      "source": [
        "# Metrics\n",
        "\n",
        "Finally, we want to evaluate the accuracy of our model. To do this, we apply the evaluate method upon our model and pass the test images and labels as parameters.\n",
        "\n",
        "## Test Loss\n",
        "\n",
        "The Test Loss Function is a measure of how well a trained machine learning model performs on the test set. The test loss helps evaluate the generalization ability of the model. A lower test loss indicates that the model's predictions are closer to the true labels, suggesting that the test set has a good performance.\n",
        "\n",
        "## Metrics\n",
        "\n",
        "The **Accuracy metric**, as mentioned previously, measures the proportion of correctly classified samples out of the total samples. The Accuracy of the test dataset can be seen below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TvzBzArAtv3",
        "outputId": "c5159ef3-b2e6-44f7-f3f8-8de970324828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9770 - loss: 0.0748\n",
            "Test Loss: 0.06127774715423584\n",
            "Test Accuracy: 98.18999767303467%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_acc * 100}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
